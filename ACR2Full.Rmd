---
title: "ACR2Full"
output:  pdf_document
author: "Martin Cavarga"
date: "`r format(Sys.time(), '%d %B, %Y')`"
---
\fontsize{10}{10}
\small

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=FALSE}
pkgTest <- function(x) {
  if (!require(x,character.only = TRUE)) {
    install.packages(x, dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}
```

# Advanced Methods of Time Series Analysis Applied to Quarterly Estimates of Unemployment Rate

## Introduction

The chosen source of data is the Labour Force Survey (LFS) quarterly estimates of unemployment rate in the UK since March 1971, up to March 2018.

---------------------------------------------------------------------------------------

## 1. Elementary Modeling by an AR Process

We begin by extracting the data from a downloaded file

```{r getData}
setwd("./")
dat <- read.table("LFS_unemployment.csv", header=F, skip=6, sep = ",", as.is = T)
dat <- dat[50:239,]
names(dat) <- c("quartile", "unemp")
dat$time <- dat$quartile[grepl('\\d{4}\\sQ\\d', dat$quartile)]

data.frame(head(dat$time)) # how the quarterly data looks

months <- (as.numeric(gsub("\\d{4}\\sQ(\\d)","\\1", dat$time)) - 1) * 3
data.frame(head(months))
years <- as.numeric(gsub("(\\d{4})\\sQ\\d","\\1", dat$time))
data.frame(head(years))
years <- years + months / 12
data.frame(head(years)) # how the time data should look

dat$time <- years
```

### 1.1: Data Plot

```{r initDataPlot, fig.width=10, fig.height=5}
plot(x=dat$time, y=dat$unemp, type="l", lwd=2, xlab="year", ylab = "unemployment [%]", 
     main="Unemployment Rate (quarterly)")
```

Now even thought we are working with annual data there should not be any seasonal components or trend
since the results do not depend on periodic observable phenomena, but rather the complex economic 
situation over multiple decades. Also the data may include exponentially decaying decrease in unemployment,
but only after year 1980, which would suggest a regime-switching stochastic process. 

### 1.2: Test Part and Evaluation Part of the Time Series

Now we separate the time series into test part, where a suitable model of a stochastic process will
be found, and the evaluation part, where predictions given by such model are evaluated. Since our
dataset contains quarterly data, we choose the length of the evaluation part of the time series as 
$L = k * 4$ where k is an arbitrary (and sufficiently small) positive integer.

```{r}
k = 5 # how many years
( L = k * 4 )
N = length(dat$unemp)
unempseries <- list(unempts = ts(dat$unemp))

unempseries$test = window(unempseries$unempts, start=1, end=N - L, extend=T)
unempseries$eval = window(unempseries$unempts, start=N - L + 1, end=N, extend=T)
```

```{r testEvalPlot, fig.width=9, fig.height=4}
par(mfrow=c(1,1))
plot(x=dat$time, y=dat$unemp, main="Test and Evaluation Part of the Quarterly Series", 
     xlab="year", ylab="unemployment [%]",type="l")
lines(head(dat$time, n = N - L), unempseries$test, col="red", lwd=2)
lines(tail(dat$time, n = L), unempseries$eval, col="blue", lwd=2)
legend("topright", legend=c("test","eval"), col=c("red","blue"), lty=1, lwd=2, cex=0.8)
```

### 1.3: Mean, Variance, ACF, and PACF of the Test Part

```{r}
stat <- summary(as.numeric(dat$unemp)[1:(N - L)])
stddev <- var(unempseries$test, na.rm = TRUE)
v <- as.numeric(c(stat[1], stat[6], stat[4], stat[3], stddev))
names(v)<-c("Min.","Max.","Mean","Median","Variance")
v
```

```{r ACFplot1, fig.width=9, fig.height=4}
par(mfrow=c(1,2))
acf(as.numeric(unempseries$test), lag.max=N, main="unemp. ACF")
acf(as.numeric(unempseries$test), lag.max=N, type="partial",main="unemp. PACF")
```

As we mentioned in section 1.1, the underlying process which gave rise to the observed results is aperiodic,
yet it is undoubtedly a process with memory. Unemployment rate strongly depends (aside from other important aspects)
on its own history which might extend generations into the past. The results are, however, significantly influenced
by external phenomena, such as the global economic crisis in late 2000's.

### 1.4: Finding a Suitable AR Model

Since the economic situation and the job market remembers its past, we choose a simple $AR(p)$ process with parameter p
corresponding to the number of steps after which the process still "remembers" its past. 
The inbuilt `ar()` function automatically finds the model with the lowest AIC (Akaike's Information Criterion). 
And by plotting the `$aic` parameter we obtain differences $AIC_{min} - AIC_k$ for all models.

```{r AICplot1, fig.width=10, fig.height=4}
kmax = 30 # set a maximum order

model <- list()
model$ar<- ar(as.numeric(unempseries$test), order.max=kmax)


par(mfrow=c(1,2))
plot(0:(length(model$ar$aic)-1), xlab="p", model$ar$aic, ylab="dAIC", main="Differences in AIC")
tmp <- sapply(1:kmax, function(x) ar(as.numeric(unempseries$test), aic=F, order.max=x)$var.pred)
plot( tmp, xlab="p", ylab="sigma^2", main="Residual variances")
```

As we can see in the figures, the lowest variance of residues corresponds to an $AR(3)$ process
with coefficients:

```{r}
rbind(coef=model$ar$ar, se=sqrt(diag(model$ar$asy.var.coef))) 

( p <- model$ar$order )
```

Unfortunately, the `ar` function does not return fitted values, thus we need to model the time series via the
`arima` function using the AR order `p` from the previous result.

```{r FitARPlot, fig.width=10, fig.height=4}
suppressMessages(pkgTest("forecast"))
( model$AR <- arima(as.numeric(unempseries$test), order=c(p, 0, 0)) )
unempseries$ARfit <- fitted(model$AR)
unempseries$ARresid <- residuals(model$AR)


par(mfrow=c(1,2))
plot(x=dat$time[1:(N - L)], y=unempseries$test, 
     main="Fitted Values of the Test Part", 
     xlab="year", ylab="unemployment [%]",type="p")
lines(x=dat$time[1:(N - L)], y=unempseries$test, col="blue", lwd=2)
legend("topright", legend=c("AR"), col=c("blue"), lty=1, lwd=2, cex=0.8)
plot(x=dat$time[1:(N - L)], y=unempseries$ARresid, main="AR Residuals", xlab="year", 
     ylab="unemployment [%]", type="l")
```

The given AR model seems to fit the time series very well, which may be due to its low oscillation rate.

### 1.5: 1-Step Predictions Over the Evaluation Part

```{r PredictionsARPlot, fig.width=8, fig.height=3}
tmp <- Arima(as.numeric(dat$unemp), model = model$AR)
model$ARpred <- window(fitted(tmp), start = N - L + 1)

( RMSE <- sqrt(mean((as.numeric(unempseries$eval) - as.numeric(model$ARpred))^2)) )

par(mfrow=c(1,1))
plot(x=dat$time[(N - L + 1):N], y=dat$unemp[(N - L + 1):N], 
     main=paste("Prediction AR(",p,"), RMSE = ",round(RMSE, digits = 4)), 
     xlab="year", ylab="unemployment [%]",type="p", pch=20)
lines(x=dat$time[(N - L + 1):N], y=model$ARpred, lwd=2.5, col="blue")
```

### 1.6.: Conclusion

Since it has very low rate of local oscillation, but does not have an easily predictable systematic pattern,
the analyzed unemployment rate time series seems to be well-estimated by an $AR(3)$ process with low prediction errors.
However, as we mentioned earlier we might be dealing with a 'regime-switching' process. 
Further analysis will be carried out in the next chapter.

---------------------------------------------------------------------------------------

## 2. Finding the Parameters of a SETAR Model

As we mentioned, the unemployment time series might be a result of a regime-switching process. Naturally, the behavior
 of the unemployment rate in a given country should depend on the current economic situation. The change in the local economy
can be described via a set of "thresholds" which determine whether the stochastic process changes its regime. The regime of
a stochastic process is defined as a unique ARMA or any other linear stochastic process with unique parameters. We begin 
by finding the parameters of a Self-Exciting Threshold Autoregressive (SETAR) process, that is: a process whose regime 
is described by a random variable determined by the very process itself, more specifically its history of up to d steps behind,
which in an essence means that the process "influences its regime" up to d time steps into the future.

For the purposes of this analysis we consider only 2 regimes, namely the regime of "job crisis" when the unemployment rate may 
fluctuate or drop more wildly compared to the regime of "job stability" when the unemployment rate stabilizes or grows.

### 2.1: Implementation of Useful Functions

First, we define a, so called, "indicator function" which essentially returns a boolean value from a given input process
  value `x` and threshold value `c`:

```{r, echo=T}
Indicator <- function(x, c) ifelse(x > c, 1, 0)
```

Afterwards, we define the basis function for a single regime
 
```{r, echo=T}
Yt <- function(x, t, p) c(1, x[(t - 1):(t - p)])
```

which can then be used in the "basis" for two regimes:

```{r, echo=T}
Xt <- function(x, t, p, d, c, z = x) {  
  # z is the threshold variable 
  I <- Indicator(z[t - d], c)
  Y <- Yt(x, t, p)
  c((1 - I) * Y, I * Y)
}
```

We can test the function on a given subset of the unemployment time series. Due to the fact that the
examined time series is rather 'smooth', for further use, we will examine its differences:

```{r, echo=T}
xt <- na.omit(diff(as.numeric(dat$unemp))) # take differences in data
x_train <- xt[seq_along(unempseries$test)] # extract test part
nt <- length(x_train)
x_eval <- xt[(nt + 1):length(xt)] # extract eval part
xt <- x_train # set the source data to test part values
```

```{r}
d <- 1; t <- 3;
xt[(t - d): t]
Xt(xt, t, p, d, c = 0)

t <- 100;
xt[(t - d): t]
Xt(xt, t, p, d, c = 0)
```

As we can see, in the first case, with time series values crossing zero from above, the latter half of the
coefficient vector gets expressed, corresponding to the series assuming the second regime.

Then we need a function defining a deterministic skeleton of the model:

```{r, echo=T}
SkeletonSETAR <- function(x, t, p, d, c, theta, z = x) theta %*% Xt(x, t, p, d, c, z)
```

where `theta` corresponds to the parameter vector, for example:

```{r}
SkeletonSETAR(xt, t, p, d, c = 0, c(1, 1, 1, 1, 1, 1, 1, 1))
```

and the last group of functions we need for the upcoming procedure are functions for the information criteria
of a SETAR model:

```{r, echo=T}
# Akaike
AIC_SETAR <- function(orders, regimeDataCount, resVariances) {
  sum(regimeDataCount * log(resVariances) + 2 * (orders + 1))
}

# Bayesian
BIC_SETAR <- function(orders, regimeDataCount, resVariances) {
  sum(regimeDataCount * log(resVariances) + log(regimeDataCount) * (orders + 1))
} 

#' and test it out:

AIC_SETAR(c(2, 2), c(10, 10), c(0.5, 0.7))
BIC_SETAR(c(2, 2), c(10, 10), c(0.5, 0.7))
```

### 2.2: The Estimation of Parameters of a SETAR Model

Given a dataset `x` and parameters `p` (AR order), `d` (SETAR delay), and the threshold `c` we find the coefficients
of a SETAR model with these parameters by performing a multivariate linear regression. The coefficient vector `PhiParams`
is the vector of unknowns of a linear system with matrix $\textbf{X}$ and a right-hand-side vector $\textbf{y}$ 
given by the time series. Although for higher values of `p` the inversion of matrix $\textbf{X}^{\top}\textbf{X}$ (with dimensions 
 $(2p + 2) \times (2p + 2)$) might be computationally demanding, we will determine the covariance matrix, i.e.: $(\textbf{X}^{\top}\textbf{X})^{-1}$
using a function `inv` from the `matlib` package:

```{r, echo=T}
suppressMessages(pkgTest("zeallot"))
suppressMessages(pkgTest("matlib"))

EstimSETAR <- function(x, p, d, c) {

  resultModel <- list()
  resultModel$p = p; resultModel$d = d; resultModel$c = c;
  resultModel$data = x;  n = length(x);  resultModel$n = n;
  k <- max(p, d)
  
  X <- as.matrix(apply(as.matrix((k + 1):n), MARGIN=1, function(t) Xt(x, t, p, d, c) ))
  y <- as.matrix(x[(k + 1):n])
  
  A = crossprod(t(X), t(X));  b = crossprod(t(X), y)

  if (abs(det(A)) > 0.000001) {
    inv <- inv(A)
    sol_phi <- as.numeric(t(inv %*% b)); sol_se <- sqrt(diag(inv)/n);
    eps <- 0.01;
    
    # filter out those coeffs that are of the same order of magnitude as their errors
    filter <- sapply(1:(2*(p + 1)), function (i) ifelse(
      abs(sol_phi[i]) <= 2 * abs(sol_se[i]), 0, 1)
    )
    
    sol_phi <- sol_phi * filter
    sol_se <- sol_se * filter
    
    solution <- cbind(phi = sol_phi,  se = sol_se)

    resultModel$PhiParams <- solution[,1] # solving (X'X)*phi = X'y
    resultModel$PhiStErrors <- solution[,2]  # standard errors
    skel <- crossprod(X, resultModel$PhiParams); resultModel$skel <- skel;
    resultModel$residuals <- (y - skel)
    resultModel$resSigmaSq <- 1 / (n - k) * sum(resultModel$residuals ^ 2)
    
    return(resultModel)
  } else {
    return(NA)
  }
}

```

After performing this procedure for multiple parameters, i.e.: searching the discrete parameter space, we 
further process the model with minimum residual square sum. For that we'll use:

```{r, echo=T}
EstimSETAR_postproc <- function(model) {
  x <- model$data; k <- max(model$p, model$d); c <- model$c; n <- model$n;
  y <- as.matrix(x[(k + 1):n])
  skel <- model$skel; model$skel <- NULL; #skel attribute no longer needed

  model$n1 <- sum(apply(as.matrix(x), MARGIN = 1, function(xt) (1 - Indicator(xt, c))))
  model$n2 <- sum(apply(as.matrix(x), MARGIN = 1, function(xt) Indicator(xt, c)))
  
  model$resSigmaSq1 <- sum(
    apply(as.matrix(seq_along(y)), MARGIN = 1,
          function(t) ifelse((1 - Indicator(y[t], c)), (y[t] - skel[t])^2, 0))) / (model$n1 - k)
  model$resSigmaSq2 <- sum(
    apply(as.matrix(seq_along(y)), MARGIN = 1,
          function(t) ifelse(Indicator(y[t], c), (y[t] - skel[t])^2, 0))) / (model$n2 - k)
  
  model$AIC <- AIC_SETAR(c(p, p), c(model$n1, model$n2), c(model$resSigmaSq1, model$resSigmaSq2))
  model$BIC <- BIC_SETAR(c(p, p), c(model$n1, model$n2), c(model$resSigmaSq1, model$resSigmaSq2))
  
  return(model)
}
```

and now we test the function for suitable parameters:

```{r}
model <- EstimSETAR(xt, 2, 2, c=0)
```

```{r, echo=T}
str( model <- EstimSETAR_postproc(model) )
```

It should be noted that for some values of `p` and `d` the indices of arrays in the algorithms might 
get out of the range of regularity for the linear system. For that reason we implement exceptions for
the outputs of `EstimSETAR` in the following algorithm.

### 2.3: SETAR Parameter Estimation Procedure

To answer the question: 'how does one find the right parameters `p`, `d` and `c` for their desired SETAR model?',
we implement the following procedure:

```{r, echo=T}
pmax <- 7 # set maximum order p
# limit the c parameter by the 7.5-th and 92.5 percentile
cmin <- as.numeric(quantile(xt, 0.075)); cmax <- as.numeric(quantile(xt, 0.925));
h = (cmax - cmin) / 100 # determine the step by which c should be iterated
models <- list()
modelColumns <- list()
for (p in 1:pmax) {
  for (d in 1:p) {
    pdModels <- list()
    for (c in seq(cmin, cmax, h)) {
      tmp <- EstimSETAR(xt, p, d, c) # try to run the function
      # then test whether it returns`NA` as a result
      if (!as.logical(sum(is.na(tmp))) ) {
        pdModels[[length(pdModels) + 1]] <- tmp
      }
    }
    sigmas <- as.numeric(lapply(pdModels, function(m) m$resSigmaSq))
    orders <- order(sigmas)
    # only the model whose parameter c gives the lowest residual square sum is chosen for postprocessing
    min_sigma_model <- EstimSETAR_postproc(pdModels[[ orders[1] ]])
    models[[length(models) + 1]] <- min_sigma_model
    modelColumns[[length(modelColumns) + 1]] <- c(
      p, d, min_sigma_model$c,
      min_sigma_model$n1, min_sigma_model$n2,
      min_sigma_model$AIC, min_sigma_model$BIC,
      min_sigma_model$resSigmaSq)
  }
}
```

```{r}
modelColumns <- data.frame(matrix(unlist(modelColumns), nrow=length(modelColumns), byrow=T))
names(modelColumns) <- c(
  "p", "d", "c",
  "n1", "n2", "AIC", "BIC",
  "resSigmaSq"
)
head(modelColumns, n=12)
```

Now we have a set of models in their original order. To find the best suitable model, we choose
12 models with the lowest BIC (Bayesian Information Criterion):

```{r}
BICs <- sapply(models, function(m) m$BIC)
orders <- order(BICs)
modelColumns <- modelColumns[orders,]
head(modelColumns, n=12)
```

and we can also include errors of the estimated regression coefficients:

```{r}
modelCoeffErrors <- list()
for(i in 1:12) {
  p <- models[[ orders[i] ]]$p
  d <- models[[ orders[i] ]]$d
  c <- models[[ orders[i] ]]$c
  key <- paste(p, d, round(c, digits=4), sep="/")
  modelCoeffErrors[[key]] <- rbind(t(models[[ orders[i] ]]$PhiParams),
                                   t(models[[ orders[i] ]]$PhiStErrors))
  row.names(modelCoeffErrors[[key]]) <- t(c("Phi", "stdError"))
}
modelCoeffErrors
```

We can now visualize the results of the top 3 models:

```{r SETARTop3Plot, fig.width=9, fig.height=4}
plotNmax <- 75
par(mfrow=c(1,2))
for (i in 1:3) {
  model <- models[[orders[i]]]
  SetarFit <- xt - append(matrix(0., ncol=model$p), model$residuals)
  m <- length(model$residuals)

  plot(x=dat$time[1:plotNmax], y=xt[1:plotNmax],
       main=paste("SETAR(",model$p,",",model$d,",",round(model$c, digits=4),")"), xlab="year", ylab="%")
  lines(x=dat$time[1:plotNmax], y=SetarFit[1:plotNmax], col="blue",lwd=2)
  legend("topleft", legend=c("fitted SETAR"), col=c("blue"), lty=1, lwd=2, cex=0.8)
  
  plot(x=dat$time[1:plotNmax], y=model$residuals[1:plotNmax], type="l", 
       main=paste("SETAR(",model$p,",",model$d,",",round(model$c, digits=4),") Residuals"),
       xlab="year", ylab="%")
}
```

The results suggest that the best SETAR models have a threshold `c` quite close to zero and more-or-less the same
RSS. The very first with a lower `BIC` (Bayesian Information Criterion), has slightly
larger RSS than the models that come after it. To verify the correctness of our procedure we will need to compare it
with inbuilt functions from a verified library.

### 2.4: SETAR Equilibria and Equilibrium Simulations

It is also essential to find out whether the skeletons of the selected SETAR models have some equilibria.
The estimation of the exact equilibria of the piecewise-linear skeletons with $p = 1$ is straightforward: We find the fixed points
of the skeletons by finding the intersections between their graphs and the identity line $\text{id} x = x$, given the model parameters
(coefficients). However, the  results of our search have mostly higher AR degrees, thus we will need to determine the models'
equilibria using a more general method, namely letting the model skeletons evolve with multiple input initial conditions.

```{r SETARTop3Equilibria, fig.width=9, fig.height=3.5}
xmax <- 0.5; xmin <- -0.2;
n <- length(xt)
simPlotMax <- 3 * n
par(mfrow=c(1,2))
for (i in 1:3) {
  equilib_sims <- list()
  equilibria <- list()
  p <- models[[orders[i] ]]$p; d <- models[[orders[i] ]]$d; c <- models[[orders[i] ]]$c;
  sigmaSq <- models[[orders[i] ]]$resSigmaSq
  k <- max(p, d)
  n_offsets <- 20
  for (j in 0:n_offsets) {
    x0 <- (xmax - xmin) / n_offsets * j + xmin
    equilib_sim <- array()
    equilib_sim[1] <- x0
    for (t in 2:simPlotMax) {
      if (t < (k + 1)) {
        equilib_sim[t] <- equilib_sim[t - 1]
      } else {
        equilib_sim[t] <- SkeletonSETAR(equilib_sim, t, p, d, c, t(models[[orders[i]]]$PhiParams))
      }
    }
    
    equilibrium_rounded <- round(equilib_sim[simPlotMax], digits=4)
    equilibria[[paste(equilibrium_rounded)]] <- equilibrium_rounded
    equilib_sims[[j + 1]] <- equilib_sim
    
    if (j < 1) {
      plot(x=1:simPlotMax, y=equilib_sim, type="l", col="gray", 
           xlim=c(1, n / 6), ylim=c(1.1 * xmin, 1.1 * xmax), 
           main=paste("SETAR(",models[[orders[i] ]]$p,",",models[[orders[i] ]]$d,",",
                      round(models[[orders[i] ]]$c, digits=4),")"),
           xlab="t", ylab="%")
    } else {
      lines(x=1:simPlotMax, y=equilib_sim, col="gray")
    }
  }
  for (j in 0:n_offsets) {
    epsilon <- (xmax - xmin) * 0.025
    x0 <- c + (n_offsets / 2 - j) * epsilon #small initial perturbations from the threshold value
    equilib_sim <- array()
    equilib_sim[1] <- x0
    for (t in 2:simPlotMax) {
      if (t < (k + 1)) {
        equilib_sim[t] <- equilib_sim[t - 1]
      } else {
        equilib_sim[t] <- SkeletonSETAR(equilib_sim, t, p, d, c, t(models[[orders[i]]]$PhiParams))
      }
    }
    equilib_sims[[j + 1]] <- equilib_sim
    lines(x=1:simPlotMax, y=equilib_sim, lwd=2)
    lines(x=c(1, simPlotMax), y=c(c, c), col="green", lty="dashed", lwd=2)
  }
  
  models[[orders[i] ]]$equilibria <- as.numeric(equilibria)
}

modelEquilibria <- sapply(1:3, function(i) models[[orders[i] ]]$equilibria)
names(modelEquilibria) <- sapply(1:3, function(i) 
  paste("SETAR(", p, ",", d, ",", round(c, digits=3), ") equilibria"))
modelEquilibria
```

As we see, the trajectories of the top 3 models gravitate towards 0 in all models, but in the first and second model they can end up in one more position, close to zero.
It might also be interesting to see how the trajectories evolve when we add an iid noise on top of the model skeleton. First we observe the skeleton behavior in our data:

```{r SETARSkeletTop3Data, fig.width=9, fig.height=4}
par(mfrow=c(1,1))

plot(x=dat$time[1:plotNmax], y=xt[1:plotNmax],
     main="Skeletons of Chosen Models With the Provided Data", xlab="year", ylab="%")
for (i in 1:3) {
  s <- array()
  k <- max(models[[orders[i]]]$p, models[[orders[i]]]$d)
  for (t in (k + 1):plotNmax) {
    tmp <- try(SkeletonSETAR(xt, t, models[[orders[i]]]$p, models[[orders[i]]]$d, 
                             models[[orders[i]]]$c, t(models[[orders[i]]]$PhiParams)),
               silent=T)
    if (class(tmp) == "try-error") {
      s[t - k] <- NA
    } else {
      s[t - k] <- tmp
    }
  }
  lines(x=dat$time[(k + 1):plotNmax], y=s[1:(plotNmax - k)], col=c("blue","purple","red")[i],lwd=2)
}
legend("topleft", legend=c(paste("SETAR(",models[[orders[1] ]]$p,",",models[[orders[1] ]]$d,",",
                                 round(models[[orders[1] ]]$c, digits=4),")"),
                           paste("SETAR(",models[[orders[2] ]]$p,",",models[[orders[2] ]]$d,",",
                                 round(models[[orders[2] ]]$c, digits=4),")"),
                           paste("SETAR(",models[[orders[3] ]]$p,",",models[[orders[3] ]]$d,",",
                                 round(models[[orders[3] ]]$c, digits=4),")")), 
       col=c("blue","purple","red"), lty=1, lwd=2, cex=0.8)
```

And then we carry out multiple simulations with initial conditions close to the threshold. The added noise will have the same deviance as the
residual square sum.

```{r SETARsimulations, fig.width=9, fig.height=4}
xmax <- 5 * max(xt); xmin <- min(xt) - 0.5 * xmax;
xmax0 <- max(xt); xmin0 <- min(xt)
par(mfrow=c(1,2))
for (i in 1:3) {
  equilib_sims <- list()
  p <- models[[orders[i] ]]$p; d <- models[[orders[i] ]]$d; c <- models[[orders[i] ]]$c;
  sigmaSq <- models[[orders[i] ]]$resSigmaSq
  k <- max(p, d)
  n_offsets <- 10
  for (j in 0:n_offsets) {
    x0 <- (xmax - xmin) / n_offsets * j - 0.5 * (xmax - xmin)
    equilib_sim <- array()
    equilib_sim[1] <- x0
    for (t in 2:plotNmax) {
      if (t < (k + 1)) {
        equilib_sim[t] <- equilib_sim[t - 1] + rnorm(1, 0, sqrt(sigmaSq))
      } else {
        equilib_sim[t] <- SkeletonSETAR(equilib_sim, t, p, d, c, t(models[[orders[i]]]$PhiParams)) +
          rnorm(1, 0, sqrt(sigmaSq))
      }
    }
    equilib_sims[[j + 1]] <- equilib_sim
    if (j < 1) {
      plot(x=dat$time[1:plotNmax], y=equilib_sim, type="l", col="gray", 
           ylim=c(1.5 * xmin, 1.5 * xmax), 
           main=paste("SETAR(",models[[orders[i] ]]$p,",",models[[orders[i] ]]$d,",",
                      round(models[[orders[i] ]]$c, digits=4),")"),
           xlab="year", ylab="%")
    } else {
      lines(x=dat$time[1:plotNmax], y=equilib_sim, col="gray")
    }
  }
  for (j in 0:n_offsets) {
    epsilon <- (xmax - xmin) * 0.025
    x0 <- c + (n_offsets / 2 - j) * epsilon #small initial perturbations from the threshold value
    equilib_sim <- array()
    equilib_sim[1] <- x0
    for (t in 2:plotNmax) {
      if (t < (k + 1)) {
        equilib_sim[t] <- equilib_sim[t - 1] + rnorm(1, 0, sqrt(sigmaSq))
      } else {
        equilib_sim[t] <- SkeletonSETAR(equilib_sim, t, p, d, c, t(models[[orders[i]]]$PhiParams)) +
          rnorm(1, 0, sqrt(sigmaSq))
      }
    }
    equilib_sims[[j + 1]] <- equilib_sim
    lines(x=dat$time[1:plotNmax], y=equilib_sim, lwd=2)
    lines(x=c(dat$time[1], dat$time[plotNmax]), y=c(c, c), col="green", lty="dashed", lwd=2)
  }
  # comparison of the original data with the simulation of the original time series
  
  x0 <- xt[1]
  equilib_sim <- array()
  equilib_sim[1] <- x0
  for (t in 2:plotNmax) {
    if (t < (k + 1)) {
      equilib_sim[t] <- equilib_sim[t - 1] + rnorm(1, 0, sqrt(sigmaSq))
    } else {
      equilib_sim[t] <- SkeletonSETAR(equilib_sim, t, p, d, c, t(models[[orders[i]]]$PhiParams)) +
        rnorm(1, 0, sqrt(sigmaSq))
    }
  }
  simMax <- max(equilib_sim, xmax0); simMin <- min(equilib_sim, xmin0);
  plot(x=dat$time[1:plotNmax], y=xt[1:plotNmax], type="l", lwd=1.5, ylim=c(simMin, 1.1 * simMax), 
       main=paste("Simulation SETAR(",models[[orders[i] ]]$p,",",models[[orders[i] ]]$d,",",
                  round(models[[orders[i] ]]$c, digits=4),")"),
       xlab="year", ylab="%")
  lines(x=dat$time[1:plotNmax], y=equilib_sim, col="purple", lwd=2)
  lines(x=c(dat$time[1], dat$time[plotNmax]), y=c(c, c), col="green", lty="dashed", lwd=2)
  legend("topleft", legend=c("original ts","simulated SETAR","threshold"), col=c("black","purple","green"), 
         lty=c(1,1,2), lwd=2, cex=0.8)
}
```

The trajectories of all of the first three models seem to gravitate toward `0` significantly fast (or alternatively:
towards their threshold values which are close to zero as well). The relatively low oscillation rate of the original 
time series suggests that the differences of this time series will, at most, fluctuate around 0. The change between 
the 'high' and 'low' regimes does not seem very significant, at leat on the larger scale. The validity of the model 
will be tested in chapter 3.

### 2.5: Comparison Of the Results With Inbuilt Functions

To verify the correctness of our methods we proceed to construct the top 3 SETAR models by plugging their parameters into 
inbuilt functions:

```{r selectSetar1, echo=T, fig.width=10, fig.height=4}
suppressMessages(pkgTest("tsDyn"))

#Testing a function which selects an orders automatically:
mmax <- 2

par(mfrow=c(1,1))
( result1 <- selectSETAR(xt, m=mmax, thDelay=0:(mmax-1), criterion="BIC", same.lags=T, trim=0.1)  )
```

the estimated thDelay corresponds to `d-1`. 

```{r}
tmp <- EstimSETAR(xt, 2, 1, -0.1)
tmp <- EstimSETAR_postproc(tmp)
str(tmp)
```

Note that we set `thDelay=0:(mmax-1)` instead of `1:mmax`. `selectSETAR` uses `thDelay = 0` for step `d=1` delay
correspondence: $x_{t-d} < c$ or $x_{t-d} > c$.
the resulting BIC's are different, possibly due to the package using a different formula

```{r selectSetar2, fig.width=10, fig.height=10}
mmax <- pmax

par(mfrow=c(1,1))
invisible(capture.output( result2 <- selectSETAR(xt, m=mmax, thDelay=0:(mmax-1), criterion="BIC", same.lags=T, trim=0.1, plot=F)  ) )
result2
```

Setting higher `mmax`, the function returns a list of models similar to the one given by our procedure in section 2.3.
We can also compare the accuracy of the computation of the regression coefficients in our `EstimSETAR` method, with
for example: `setar()` function (from `tsDyn` library as well):

```{r, echo=T}
setars <- list()
coeffComparison <- list()
resSigmaComparison <- list()
n <- length(xt)
for (i in 1:3) {
  p <- models[[ orders[i] ]]$p
  d <- models[[ orders[i] ]]$d
  c <- models[[ orders[i] ]]$c
  setars[[i]] <- setar(xt, m=p)
  k <- max(p, d)
  resSigmaComparison[[i]] <- c(
    (1 / (n - k) * sum(setars[[i]]$residuals ^ 2)), 
    models[[ orders[i] ]]$resSigmaSq
    )
  inbuiltParams <- t(setars[[i]]$coefficients)
  key <- paste(p, d, round(c, digits=4), sep=" / ")
  coeffComparison[[key]] <- rbind(
    inbuiltParams, 
    t(append(models[[orders[i]]]$PhiParams, models[[orders[i]]]$c))
  )
  row.names(coeffComparison[[key]]) <- t(c("inbuilt", "custom"))
}
coeffComparison

# comparing RSS

resSigmaComparison <- data.frame(matrix(unlist(resSigmaComparison), nrow=3, byrow=T))
colnames(resSigmaComparison) <- c("inbuilt", "custom")
row.names(resSigmaComparison) <- t(paste("rss",1:3))
resSigmaComparison
```

Without specifying the threshold value, the inbuilt `setar` function finds threshold values quite close
to those of our custom procedures. The AR order `p` for both regimes, however, has to be specified in advance.
The comparison of the model coefficients suggests that our custom method was more-or-less accurate. 

### 2.6: Conclusion

The results of the SETAR Parameter Estimation Procedure in section 2.3 show that the 3 best 2-regime SETAR
models are:

```{r top3conc}
results <- list()
for (i in 1:3) {
  p <- models[[ orders[i] ]]$p
  d <- models[[ orders[i] ]]$d
  c <- round(models[[ orders[i] ]]$c, digits=4)
  results[[i]] <- paste("SETAR(", p,",", d,",", c,")" )
}
data.frame(unlist(results))
```

The first model with the lowest 
`BIC` (Bayesian Information Criterion) has the most accurate estimation of its 4 regression parameters, 
with the highest residual square sum. The first model seems to have a stable equilibrium at their threshold values.

--------------------------------------------------------------------------------------------------------------

## 3: Tests of Linearity/Nonlinearity of SETAR models

We need to make sure a non-linear model (SETAR, for example) is really suitable for describing the process. 
In order to find out, we test the null hypothesis that a linear model is more suitable than a non-linear one. 
In the case of a 2-regime model we are looking for, so called, nuisance parameters, i.e.: $H_0: \Phi_1 = \Phi_2$ where
$\Phi_1$ and $\Phi_2$ are the parameters of the low and the high regime respectively.

### 3.1: Hansen's Conditions

Hansen proposed three conditions to test whether a SETAR model can be tested for linearity using the so called
Likelihood-Ratio (LR) test:

```{r, echo=T}
Hansen <- function(d, c, Phi) {
  p <- (length(Phi)/2) - 1
  #separate regimes into rows
  Phi <- do.call(rbind, split(Phi,rep(1:2,each=(p + 1))))
  # (p10-p20)+(p1d-p2d)*c <= 0
  c1 <- !isTRUE(all.equal( 0, apply(Phi[,c(1,1 + d),drop=F],2, diff) %*% c(1,c) ))
  # p1j neq p2j, j notin {0,d}
  c2 <- all(apply(Phi[,-c(1,1 + d),drop=F], 2, function(x) !identical(0, diff(x))))
  # sum_j|pij| < 1 forall i=1,2
  c3 <- all(apply(Phi[,-1,drop=F], 1, function(x) sum(abs(x))) < 1)
  c(cond1=c3, cond2=c2, cond3=c3)
}
```

If all three are satisfied the model can be tested using the LR test:

```{r}
hansenResults <- matrix(NA, ncol=3, nrow=12)
keys <- array()
for (i in 1:12) {
  p <- models[[ orders[i] ]]$p
  d <- models[[ orders[i] ]]$d
  c <- models[[ orders[i] ]]$c
  keys[i] <- paste(p, d, round(c, digits=3), sep=" / ")
  hansenResults[i,] <- Hansen(d, c, models[[ orders[i] ]]$PhiParams)
}
row.names(hansenResults) <- keys
colnames(hansenResults) <- c("cond1","cond2","cond3")

hansenResults
```

It appears that only the first and the fifth model can be tested using the LR test. The rest will have to be 
assessed using the Lagrange Multiplier (LM) test.

### 3.2: LR and LM Tests

In this section we formulate the basic procedures for the LR (Likelihood Ratio), and LM (Lagrange Multiplier) tests:

```{r, echo=T}
LRtest <- function(x, p, var, alpha=0.05) {
  tmp <- ar(x, aic=F, order.max=pmax, method = "ols")
  tmp <- tmp$var.pred  # linear model residual variance
  testat <- length(x)*(tmp-var)/tmp  # test statistic
  CDF <- Vectorize( function(t) {  # test statistic CDF
    fun <- function(t) 1 + sqrt(t/(2*pi))*exp(-t/8) + 1.5*exp(t)*pnorm(-1.5*sqrt(t)) -
      (t+5)*pnorm(-sqrt(t)/2)/2
    if(abs(t)>300 || is.infinite(t)) return(sign(t))
    if(t >=0 ) fun(t) else 1-fun(-t)
  })
  # for alpha=2.5%: CV=11.03329250
  if(alpha==0.05) critval <- 7.68727553
  else critval <- uniroot(function(x) CDF(x) - (1-alpha), c(-1000,1000))$root
  # (test statistics, critical value, p-value)
  c(TS=testat, CV=critval, p_value=1-CDF(testat))
}

LRtest(xt, models[[ orders[1] ]]$p, models[[ orders[1] ]]$resSigmaSq)
```

```{r, echo=T}
suppressMessages(pkgTest("dynlm"))

LMtest <- function(x, p, d, alpha = 0.05) {
  # prevent from passing (accidental and needless) name to result
  names(p) <- NULL
  # if x is not a ts object, by chance
  x <- as.ts(x)
  # requires dynlm package (it can be implemented withou dynlm, see model2)
  model1 <- dynlm(x ~ L(x,1:p))
  y <- model1$residuals
  # a list of shifted time series
  tmp <- c(
    list(y),
    lapply(1:p, function(i) stats::lag(x, -i)), 
    lapply(1:p, function(i) stats::lag(x, -i)*stats::lag(x,-d)),
    list(stats::lag(x,-d)^3)
  )
  tmp <- do.call(function(...) ts.intersect(..., dframe=T), tmp)
  names(tmp) <- c("y", paste0("x",1:p), paste0("xd",1:p), "xd^3")
  # cannot be done with the dynlm package
  model2 <- lm(y ~ ., data = tmp)
  z <- model2$residuals
  testat <- (length(x)-p) * (sum(y^2)/sum(z^2) - 1)
  c(TS=testat, CV=qchisq(1-alpha, df=p+1), p_value=1-pchisq(testat, df=p+1))
}

LMtest(xt, models[[ orders[1] ]]$p, models[[ orders[1] ]]$d)
```

We can easily automate the testing procedure with the following results:

```{r}
alpha = 0.05
results <- list()
nonlinear <- list()
nonLinCount <- 0
nonLinOrders <- c()
for (i in 1:12) {
  p <- models[[ orders[i] ]]$p; d <- models[[ orders[i] ]]$d; c <- models[[ orders[i] ]]$c;
  hansenResult <- Hansen(d, c, models[[ orders[i] ]]$PhiParams)
  if (FALSE %in% hansenResult) {
    hansenResult <- FALSE
    testResult <- LMtest(xt, p, d)
  } else {
    hansenResult <- TRUE
    testResult <- LRtest(xt, p, models[[ orders[i] ]]$resSigmaSq)
  }
  if (testResult[3] < alpha) {
    nonLinCount <- nonLinCount + 1
    nonlinear[[nonLinCount]] <- models[[ orders[i] ]]
    nonLinOrders <- c(nonLinOrders, orders[i])
  }
  results[[i]] <- append(cbind(p, d, c, hansenResult), testResult)
}
results <- data.frame(matrix(unlist(results), nrow=12, byrow=T))
colnames(results) <- c("p", "d", "c", "Hansen Cond.", "TS", "CV", "p-value")
row.names(results) <- orders[1:12]
results[,4] <- as.logical(results[,4])

results
```

For significance level `alpha = 0.05` the linearity hypothesis is not rejected only for the following
models:

```{r topNullHyp}
nullHyp <- subset(results, results[,7] < 0.05)
res <- list()
for (i in 1:3) {
  p <- nullHyp$p[i]
  d <- nullHyp$d[i]
  c <- nullHyp$c[i]
  res[[i]] <- paste("SETAR(", p,",", d,",", c,")" )
}
data.frame(unlist(res))
```

The remaining models can be considered non-linear.

### 3.3 Modified LR Test Via Boostrapping

The proposed LR test has a significant drawback in the fact that it can only be done when Hansen's 
conditions are satisfied. This is due to the fact that we do not know the distribution of the resulting 
F-statistic. According to Hansen (1996), however, the distribution of a bootstrapped statistic $F*$ converges
weakly in probability to the distribution of $F$, so that repeated bootstrap draws from $F*$ can be used to
approximate the asymptotic distribution of $F$. A parallelized implementation can be seen in the following snippet:
```
  ...

  if (FALSE %in% Hansen(p, d, model$PhiParams)) {
    suppressMessages(pkgTest("tsDyn"))
    suppressMessages(pkgTest("parallel"))
    suppressMessages(pkgTest("doSNOW")) # using doSNOW package for parllel computing
    n_cores <- detectCores() - 1
    cl <- makeCluster(n_cores, type="SOCK")
    registerDoSNOW(cl)
    log <- capture.output({
      testResults <- suppressWarnings(
        setarTest(x, m=p, thDelay=0:(d - 1), nboot=nboot ,trim=0.1, test="1vs", hpc="foreach")
      )
    })
    stopCluster(cl)
    ...
  }
  ...
```
```{r}
signif_code <- function(p_val) {
  return (
    ifelse(p_val < 0.1 && p_val >= 0.05, ".",
           ifelse(p_val < 0.05 && p_val >= 0.01, "*",
                  ifelse(p_val < 0.01 && p_val >= 0.001, "**", 
                         ifelse(p_val < 0.001, "***", "")
                  )
           )
    )
  )
}

LRtest_Hansen <- function(model, alpha=0.05, nboot=100) {
  x <- model$data; p <- model$p; d <- model$d; var <- model$resSigmaSq
  linear <- ar(x, aic=F, order.max=pmax, method = "ols")
  linearVar <- linear$var.pred  # linear model residual variance
  Fstat <- length(x)*(linearVar-var)/linearVar  # test statistic

  
  if (FALSE %in% Hansen(p, d, model$PhiParams)) {
    suppressMessages(pkgTest("tsDyn"))
    suppressMessages(pkgTest("parallel"))
    suppressMessages(pkgTest("doSNOW")) # using doSNOW package for parllel computing
    n_cores <- detectCores() - 1
    cl <- makeCluster(n_cores, type="SOCK")
    registerDoSNOW(cl)
    log <- capture.output({
      testResults <- suppressWarnings(
        setarTest(x, m=p, thDelay=0:(d - 1), nboot=nboot ,trim=0.1, test="1vs", hpc="foreach")
      )
    })
    stopCluster(cl)

    p_val <- testResults$PvalBoot[1]
    boot_Fstat <- testResults$Ftests[1]
    critVal <- ifelse(alpha == 0.1, testResults$CriticalValBoot[1, 1],
                      ifelse(alpha == 0.05, testResults$CriticalValBoot[1, 2],
                             ifelse(alpha == 0.025, testResults$CriticalValBoot[1, 3],
                                    ifelse(alpha == 0.01, testResults$CriticalValBoot[1, 4], NA)
                                    )
                             )
                      )
    c(
        TS=round(boot_Fstat, digits=4),
        CV=round(critVal, digits=4),
        p_value=round(p_val, digits=6),
        signif=signif_code(p_val)
      )
  } else {
    CDF <- Vectorize( function(t) {  # test statistic CDF
      fun <- function(t) 1 + sqrt(t/(2*pi))*exp(-t/8) + 1.5*exp(t)*pnorm(-1.5*sqrt(t)) -
        (t+5)*pnorm(-sqrt(t)/2)/2
      if(abs(t)>300 || is.infinite(t)) return(sign(t))
      if(t >=0 ) fun(t) else 1-fun(-t)
    })
    if(alpha==0.05) critval <- 7.68727553 # for alpha=2.5%: CV=11.03329250
    else critval <- uniroot(function(x) CDF(x) - (1-alpha), c(-1000,1000))$root
    p_val = 1 - CDF(Fstat)
    c(
      TS=round(Fstat, digits=4),
      CV=round(critval, digits=4),
      p_value=round(p_val, digits=6),
      signif=signif_code(p_val)
      )
  }
}

#df <- list()
#pvals <- c(); times <- list()
#for (i in 1:12) {
#  times[[i]] <- system.time(df[[i]] <- LRtest_Hansen(models[[ orders[i] ]], nboot=100))
#  df[[i]][5] <- paste(round(times[[i]][3], digits=4),"s")
#  pvals[i] <- df[[i]][3]
#}

#df <- data.frame(matrix(unlist(df), nrow=length(df), byrow=T))
#colnames(df) <- c("TV", "CV", "p-value", "", "time")
#df

```

### 3.4 Visualisation of Non-Linear Models

From the results of the previous procedure, we will visualize the models for which the linearity
null-hypothesis was rejected based on the LR and LM tests:

```{r trueSETARs, fig.width=10, fig.height=3.9}
# par(mfrow=c(1,2))
# xmax <- max(xt); xmin <- min(xt) - 0.5 * xmax;
# xmax <- xmax + 0.2 * (xmax - xmin)
# nonLinOrders <- vector()
# for (i in 1:12) {
#   if (pvals[i] < alpha) {
#     nonLinOrders <- c(nonLinOrders, orders[i])
#     p <- models[[ orders[i] ]]$p
#     d <- models[[ orders[i] ]]$d
#     c <- models[[ orders[i] ]]$c
#     x0 <- as.numeric(unempseries$test)[1]
#     fitted <- xt[1:(N - L)] - models[[ orders[i] ]]$residuals[1:(N - L)]
#   
#     plot(x=dat$time[1:(N - L)], y=xt[1:(N - L)], ylim=c(xmin, xmax),
#        main=paste("SETAR(",p,",",d,",",round(c, digits=4),")"), 
#        xlab="year", ylab="diff(unemp) [%]",type="p")
#     lines(x=dat$time[1:(N - L)], y=fitted, lwd=2, col="royalblue2")
#     lines(x=c(dat$time[1], dat$time[(N - L)]), y=c(c, c), col="brown3", 
#         lty="dashed", lwd=2)
#    legend("topleft", legend=c("fitted SETAR","threshold"), col=c("royalblue2","brown3"),
#          lty=c(1,2), lwd=2, cex=0.8)
#   
#    plot(x=dat$time[1:(N - L)], y=models[[ orders[i] ]]$residuals[1:(N - L)], type="l", lwd=1.5,
#        main=paste("SETAR(",p,",",d,",",round(c, digits=4),") residuals"), xlab="year",
#         ylab="diff(unemp) [%]", ylim=c(xmin, xmax))
#    print( c(resSigmaSq = models[[ orders[i] ]]$resSigmaSq) )
#  }
#}

par(mfrow=c(1,2))
xmax <- max(xt); xmin <- min(xt) - 0.5 * xmax;
xmax <- xmax + 0.2 * (xmax - xmin)
for (i in 1:nonLinCount) {
  p <- nonlinear[[i]]$p
  d <- nonlinear[[i]]$d
  c <- nonlinear[[i]]$c
  x0 <- as.numeric(unempseries$test)[1]
  fitted <- xt[1:(N - L)] - nonlinear[[i]]$residuals[1:(N - L)]
  #diffsum <- sapply(1:(N - L), function(j) { x0 + sum(fitted[1:j]) })
  plot(x=dat$time[1:(N - L)], y=xt[1:(N - L)], ylim=c(xmin, xmax),
       main=paste("SETAR(",p,",",d,",",round(c, digits=4),")"), 
       xlab="year", ylab="diff(unemp) [%]",type="p")
  lines(x=dat$time[1:(N - L)], y=fitted, lwd=2, col="royalblue2")
  lines(x=c(dat$time[1], dat$time[(N - L)]), y=c(c, c), col="brown3", lty="dashed", lwd=2)
  legend("topleft", legend=c("fitted SETAR","threshold"), col=c("royalblue2","brown3"), lty=c(1,2), lwd=2, cex=0.8)
  
  plot(x=dat$time[1:(N - L)], y=nonlinear[[i]]$residuals[1:(N - L)], type="l", lwd=1.5,
       main=paste("SETAR(",p,",",d,",",round(c, digits=4),") residuals"), xlab="year", ylab="diff(unemp) [%]", ylim=c(xmin, xmax))
  print( c(resSigmaSq = nonlinear[[i]]$resSigmaSq) )
}

# nonLinOrders
```

### 3.5 Conclusion

Since the differences in the unemployment rate have been used, we show the threshold value as well as the fitted values of the 
models in the same plot. The switching between the high and the low regimes can is clearly visible for all the selected models
(perhaps, except the second one, with its threshold value quite close to zero ). It is not yet clear whether another regime
should be present in the stochastic process. This will be assessed in the following chapter.

## 4. 3-Regime SETARs and Diagnostic Tests of SETAR Models

The next step in the analysis using SETAR models is verifying whether 2 regimes suffice. If they do not, we will have 
to consider the possibility that a third regime needs to be added. In that case, we need to write methods for such model

### 4.1 Useful Functions

```{r, echo=T}
# the indicator function for 3 regimes:
Indicator3 <- function(x, c) {
  tmp <- rep(F,3)
  tmp[findInterval(x, c, left.open = T) + 1] <- T
  tmp
}

Indicator3(-4, c(-1,1))
Indicator3(0, c(-1,1))
Indicator3(4, c(-1,1))

# SETAR3 basis vector
Yt3 <- function(x, t, p) c(1, x[(t - 1):(t - p)])

# SETAR3 skeleton
Xt3 <- function(x, t, p, d, c, z = x) {  
  # z is the threshold variable 
  I <- Indicator3(z[t - d], c)
  Y <- Yt(x, t, p)
  c(I[1] * Y, I[2] * Y, I[3] * Y)
}

# covariance matrix of the 3 regime SETAR
CovMat3 <- function(x, p, d, c) {
  n <- length(x)
  # this will become the covariance matrix
  Yc <- matrix(0., ncol = (3 * p + 3), nrow = (3 * p + 3))
  k <- max(p, d)
  for (t in (k + 1):n) {
    XT <- Xt3(x, t, p, d, c)
    Yc <- Yc + (XT %o% XT)
  }
  det <- det(Yc)
  if (det > -0.00001 && det < 0.00001) {
    return(NA)
  } else {
    return(inv(Yc))
  }
}

CovMat3(xt, p=2, d=1, c=c(-0.1, 0.2))
```


To find out, whether the third regime should be added, we need to test for the independence of residuals:

### 4.2 The Brock-Dechert-Scheinkman (BDS) Test

Regarded as the most successful tests for nonlinearity due to its universality, the BDS test relies on evaluating a correlation integral $C(q,r)$
as a measure of repeated occurrence of patterns in the time series. It is the estimate of the probability of two arbitrary $q$-dimensional
points in $\mathbb{R}^q$ being no further than $r \hat{\sigma}_\varepsilon$ apart ($0.5 \leq r \leq 1.5$). If the data is generated by an 
iid process, the correlation integral should approach $C(q,r) \rightarrow C(1, r)^q$.

```{r bdsTesting}

nlinOrders <- c() # buffer to store indices for models with possible nonlinearities
nlinNames <- c()
oldNlinOrders <- c()
for (i in 1:nonLinCount) { # length(nonLinOrders)
  test <- tseries::bds.test(na.omit(nonlinear[[i]]$residuals), m = 3)
  p <- nonlinear[[i]]$p
  d <- nonlinear[[i]]$d
  c <- nonlinear[[i]]$c
  name <- nonlinear[[i]]$name
  if ( mean(c(test$p.value) > alpha) > 0.5 ) {
    cat("possible remaining nonlinearity for",name ," with mean p-val = ", mean(c(test$p.value) > alpha), "\n")
    nlinOrders <- c(nlinOrders, i)
    oldNlinOrders <- c(oldNlinOrders, nonLinOrders[i])
    nlinNames <- c(nlinNames, name)
  } else {
    cat("remaining nonlinearity rejected ", name," with mean p-val = ", mean(c(test$p.value) > alpha), "\n")
  }
}

nonlinear <- sapply(1:length(nlinOrders), function(i) nonlinear[[ nlinOrders[i] ]])
nonLinOrders <- oldNlinOrders
cat("==== Remaining nonlinearities detected for: ======\n")

nlinNames

```

After filtering out the models with remaining nonlinearity, and since we get 3 models with the same $d$ parameter, it will be enough to build
just one SETAR3.

### 4.3 SETAR3 Parameter Estimation

Similarly to section 2.3, we construct an estimation procedure with two distinct threshold parameters $c_1$ and $c_2$. Our helper functions are ready
from section 4.1. Using them we implement:

```{r estimSETAR3, echo=T}
suppressMessages(pkgTest("zeallot"))
suppressMessages(pkgTest("matlib"))

EstimSETAR3 <- function(x, p, d, c) {
    resultModel <- list()
    resultModel$p = p; resultModel$d = d; resultModel$c = c;
    resultModel$data = x;  n = length(x);  resultModel$n = n;
    
    k <- max(p, d)
    
    X <- as.matrix(apply(as.matrix((k + 1):n), MARGIN=1, function(t) Xt3(x, t, p, d, c) ))
    y <- as.matrix(x[(k + 1):n])
    K <- CovMat3(x, p, d, c); b <- crossprod(t(X), y);
    
    if (as.logical(sum(is.na(K)))) {
      return(NA)
    } else {
      sol_phi <- as.numeric(t(K %*% b)); sol_se <- sqrt(diag(K)/n);
      eps <- 0.01;
      
      # filter out those coeffs that are of the same order of magnitude as their errors
      filter <- sapply(1:(3*(p + 1)), function (i) ifelse(
          abs(sol_phi[i]) <= 2 * abs(sol_se[i]), 0, 1
        )
      )
      
      sol_phi <- sol_phi * filter
      sol_se <- sol_se * filter
      
      solution <- cbind(phi = sol_phi,  se = sol_se)
      resultModel$PhiParams <- solution[,1] # solving (X'X)*phi = X'y
      resultModel$PhiStErrors <- solution[,2]  # standard errors
      skel <- crossprod(X, resultModel$PhiParams); resultModel$skel <- skel;
      resultModel$residuals <- (y - skel)
      resultModel$resSigmaSq <- 1 / (n - k) * sum(resultModel$residuals ^ 2)
      
      return(resultModel)
    }
}

str( test_model <- EstimSETAR3(xt, p=2, d=1, c=c(-0.1, 0.2)) )

```

After we find a suitable SETAR3 model, we implement a postprocessing method:

```{r estimSETAR3Postproc, echo=T}

EstimSETAR3_postproc <- function(model) {
    x <- model$data; k <- max(model$p, model$d); p <- model$p; c <- model$c; n <- model$n;
    y <- as.matrix(x[(k + 1):n])
    skel <- model$skel; # model$skel <- NULL; #skel attribute no longer needed
    
    # regime counts
    nRegCounts <- rowSums( matrix(as.numeric((sapply(x, function(xi) Indicator3(xi, c)))), nrow=3) )
    model$nRegCounts <- nRegCounts
    # names(model$nRegCounts) <- c("n1", "n2", "n3")
    
    # regime sigma sq:
    regSigmaSq <- rowSums( 
      matrix(
        as.numeric((sapply(y, function(xi) Indicator3(xi, c)))), nrow=3)
       %*% (y - skel)^2 ) / (nRegCounts - k)
    model$regSigmaSq <- regSigmaSq
    # names(model$regSigmaSq) <- c("rss1", "rss2", "rss3")
    
    # count valid p orders
    pOrders <- rowSums(
      matrix(as.numeric((
        sapply(1:(3 * (p + 1)), 
               function(i) ifelse( (i %% (p + 1) != 1 && model$PhiParams[i] != 0), 1, 0) )
        )
      ), nrow=3, byrow=T)
    )
    model$pOrders <- pOrders
    # names(model$pOrders) <- c("p1", "p2", "p3")
    
    model$AIC <- AIC_SETAR(pOrders, model$nRegCounts, model$resSigmaSq)
    model$BIC <- BIC_SETAR(pOrders, model$nRegCounts, model$resSigmaSq)
  
    return(model)
}

str( test_model <- EstimSETAR3_postproc(test_model) )
```

Since the number of regimes $m$ appears as a parameter in the implementation above, we can compose a generalized method for estimation
and postprocessing for any number of regimes:

```{r mRegEstim, echo=T}

Indicator_m <- function(x, c, m) {
  tmp <- rep(F, m)
  tmp[findInterval(x, c, left.open = T) + 1] <- T
  tmp
}

Xt_m <- function(x, t, p, d, c, m, z = x) {
  I <- Indicator_m(z[t - d], c, m)
  Y <- Yt(x, t, p)
  sapply(1:m, function(j) I[j] * Y)
}

# test for packages
suppressMessages(pkgTest("zeallot"))
suppressMessages(pkgTest("matlib"))


EstimSETAR_m <- function(x, p, d, c, m) {
    m = as.integer(m)
    if (m <= 0) {
      message("Error: regime count m has to be a positive integer")
      return(NA)
    }
    if (length(c) != m - 1) {
      message("Error: Incompatible dimensions of threshold vector and regime count.");
      return(NA)
    }
    
    resultModel <- list()
    resultModel$nReg <- m
    resultModel$p = p; resultModel$d = d; resultModel$c = c;
    resultModel$data = x;  n = length(x);  resultModel$n = n;
    
    k <- max(p, d)
    
    X <- as.matrix(apply(as.matrix((k + 1):n), MARGIN=1, function(t) Xt_m(x, t, p, d, c, m) ))
    y <- as.matrix(x[(k + 1):n])
    K <- crossprod(t(X), t(X)); b <- crossprod(t(X), y);
    
    detK <- abs(det(K))
    
    if (detK < 0.000001) {
      return(NA)
    } else {
      K <- inv(K)
      sol_phi <- as.numeric(t(K %*% b)); sol_se <- sqrt(diag(K)/n);
      eps <- 0.01;
      
      # filter out those coeffs that are of the same order of magnitude as their errors
      filter <- sapply(1:(m*(p + 1)), function (i) ifelse(
          abs(sol_phi[i]) <= 2 * abs(sol_se[i]), 0, 1
        )
      )
      
      sol_phi <- sol_phi * filter
      sol_se <- sol_se * filter
      
      solution <- cbind(phi = sol_phi,  se = sol_se)
      resultModel$PhiParams <- solution[,1] # solving (X'X)*phi = X'y
      resultModel$PhiStErrors <- solution[,2]  # standard errors
      skel <- crossprod(X, resultModel$PhiParams); resultModel$skel <- skel;
      resultModel$residuals <- (y - skel)
      resultModel$resSigmaSq <- 1 / (n - k) * sum(resultModel$residuals ^ 2)
      
      return(resultModel)
    }
}

EstimSETAR_m_postproc <- function(model) {
    m <- model$nReg; x <- model$data; n <- model$n;
    k <- max(model$p, model$d); p <- model$p; c <- model$c; 
    y <- as.matrix(x[(k + 1):n])
    skel <- model$skel;
    
    # regime counts
    nRegCounts <- rowSums( matrix(as.numeric( sapply(x, function(xi) Indicator_m(xi, c, m)) ), nrow=m) )
    model$nRegCounts <- nRegCounts
    
    # count valid p orders
    pOrders <- rowSums(
      matrix(as.numeric((
        sapply(1:(m * (p + 1)), 
               function(i) ifelse( (i %% (p + 1) != 1 && model$PhiParams[i] != 0), 1, 0) )
        )
      ), nrow=m, byrow=T)
    )
    model$pOrders <- pOrders
    
    k_m <- pmax(pOrders, model$d) # k-offset for different regimes
    
    # regime sigma sq:
    regSigmaSq <- rowSums( 
      matrix(as.numeric( 
        sapply(y, function(xi) Indicator_m(xi, c, m)) ), nrow=m) %*% (y - skel)^2 ) / (nRegCounts - k_m)
    model$regSigmaSq <- regSigmaSq
    # names(model$regSigmaSq) <- sapply(1:m, function(j) paste0("rss", j))
    
    model$AIC <- AIC_SETAR(pOrders, model$nRegCounts, model$resSigmaSq)
    model$BIC <- BIC_SETAR(pOrders, model$nRegCounts, model$resSigmaSq)
    
    c <- round(c, digits=3) # 3 dec. places seems enough
    model$name <- paste0("SETAR(", p, ",", d, ",", paste(na.omit(c), collapse=','), ")")
  
    return(model)
}

getModelName <- function(model) {
  p <- model$p; d <- model$d; c <- round(model$c, digits=3) # 3 dec. places seems enough
  paste0("SETAR(", p, ",", d, ",", paste(na.omit(c), collapse=','), ")")
}


str( EstimSETAR_m_postproc( EstimSETAR_m(xt, p=2, d=1, c=-0.1, m=2) ) ) # 2 regimes

str( EstimSETAR_m_postproc( EstimSETAR_m(xt, p=2, d=1, c=c(-0.1, 0.2), m=3) ) ) # 3 regimes

str( EstimSETAR_m_postproc( EstimSETAR_m(xt, p=2, d=1, c=c(-0.1, 0.1, 0.2), m=4) ) ) # 4 regimes

```

### 4.4 SETAR Estimation procedure

Now that we prepared all necessary functions we may proceed to search for 3-regime SETAR's in a suitable search space. This time
we will construct our outer loop through delays $d$ which will be reduced to only the delays that are contained within the models
with detected remaining nonlinearity:

```{r}
cat(" unique delays: ")
( delays <- unique(sapply(1:length(nonlinear), function(i) nonlinear[[i]]$d)) )
```

Still, even after this alleviation, the search might be computationally demanding. To obtain our results within reasonable time
we use `foreach` and `doParallel` packages to compute search through $c_1$ and $c_2$ thresholds, and then process the results:

```{r setar3Estim, echo=T}
m <- 3 # 3-regime setars
pmax <- 7 # set maximum order p
# limit the c parameter by the 7.5-th and 92.5 percentile
cmin <- as.numeric(quantile(xt, 0.075)); cmax <- as.numeric(quantile(xt, 0.925));
h = (cmax - cmin) / 50 # determine the step by which c should be iterated

models3 <- list()
model3Columns <- list()

suppressMessages(pkgTest("foreach"))
suppressMessages(pkgTest("doParallel"))

pkgs <- c("zeallot", "matlib")

n_cores <- (detectCores() - 1)

for (d in delays) {
  for (p in d:pmax) {
    # PARALLEL LOOP

    cl <- makeCluster(n_cores)
    registerDoParallel(cl)
    pdModels <- foreach(c1 = seq(from = cmin, to = cmax - h, by = h), .packages = pkgs) %:%
      foreach(c2 = seq(c1 + h, cmax, by = h), .packages = pkgs) %dopar% {
        # skip models with slim regime
        if(sum(xt > c1 & xt < c2) < length(xt) * 0.15) {
          NA
        } else {
          tmp <- EstimSETAR_m(xt, p, d, c(c1, c2), m) # try to run the function
          # then test whether it returns`NA` as a result
          if (!as.logical(sum(is.na(tmp))) ) {
            list(tmp)
          }          
        }
      }

    stopCluster(cl)
    
    # OLD LOOP:
    
    #pdModels <- list()
    #for(c1 in seq(from = cmin, to = cmax - h, by = h)) {
    #  for(c2 in seq(c1 + h, cmax, by = h)) {
    #    if(sum(xt > c1 & xt < c2) < length(xt) * 0.15) next # skip models with slim regime
    #    tmp <- EstimSETAR_m(xt, p, d, c(c1, c2), m) # try to run the function
    #    # then test whether it returns`NA` as a result
    #    if (!as.logical(sum(is.na(tmp))) ) {
    #      pdModels[[length(pdModels) + 1]] <- tmp
    #    }
    #  }
    #}

    # frankly, this is a mess, but I can only get this nested list from the parallel loop
    pdOmitted <- lapply(unlist(pdModels, recursive=F), 
                        function(m) if(!is.logical(m) && !is.null(m)) m else list(list(resSigmaSq = Inf)))
    sigmas <- as.numeric(lapply(pdOmitted, function(m) m[[1]]$resSigmaSq))
    s_orders <- order(sigmas)
    # only the model whose parameter c gives the lowest residual square sum is chosen for postprocessing
    min_sigma_model <- EstimSETAR_m_postproc(pdOmitted[[ s_orders[1] ]][[1]])
    
    models3[[length(models3) + 1]] <- min_sigma_model
    model3Columns[[length(model3Columns) + 1]] <- c(
      min_sigma_model$p, min_sigma_model$pOrders, d, round(min_sigma_model$c, digits=4),
      min_sigma_model$nRegCounts,
      min_sigma_model$AIC, min_sigma_model$BIC,
      min_sigma_model$resSigmaSq)
  }
}

```

```{r}
model3Columns <- data.frame(matrix(unlist(model3Columns), nrow=length(model3Columns), byrow=T))
names(model3Columns) <- c(
  "p", sapply(1:m, function(j) paste0("p", j)), "d", sapply(1:(m-1), function(j) paste0("c", j)),
  sapply(1:m, function(j) paste0("n", j)), "AIC", "BIC",
  "resSigmaSq"
)
BICs3 <- sapply(models3, function(m) m$BIC)

orders3 <- order(BICs3)
models3Out <- model3Columns[orders3,]
head(models3Out, n=12)
```

These are the SETAR3 models that can replace the SETAR2's with remaining nonlinearity, ordered by $BIC$ with estimated coefficients:

```{r}
model3CoeffErrors <- list()
for(o in orders3) {
  p <- models3[[o]]$p
  d <- models3[[o]]$d
  c1 <- models3[[o]]$c[1]; c2 <- models3[[o]]$c[2];
  key <- paste(p, d, round(c1, digits=4), round(c2, digits=4), sep="/")
  model3CoeffErrors[[key]] <- rbind(t(models3[[o]]$PhiParams),
                                   t(models3[[o]]$PhiStErrors))
  row.names(model3CoeffErrors[[key]]) <- t(c("Phi", "stdError"))
}
model3CoeffErrors
```

As we might notice, some models differ only in their information criteria and coefficients, since they were estimated from a different maximum order $p$.

### 4.5 SETAR3 Visualisation

```{r SETAR3Top3Plot, fig.width=10, fig.height=4}
plotNmax <- 100
par(mfrow=c(1,2))
for (i in 1:min(8, length(orders3))) {
  model <- models3[[orders3[i]]]
  SetarFit <- xt - append(matrix(0., ncol=model$p), model$residuals)
  c1 <- model$c[1]; c2 <- model$c[2];
  name <- model$name

  plot(x=dat$time[1:plotNmax], y=xt[1:plotNmax],
       main=name, xlab="year", ylab="%")
  lines(x=dat$time[1:plotNmax], y=SetarFit[1:plotNmax], col="blue",lwd=2)
  lines(x=c(dat$time[1], dat$time[plotNmax]), y=c(c1,c1), col="brown3", lty="dashed", lwd=2)
  lines(x=c(dat$time[1], dat$time[plotNmax]), y=c(c2,c2), col="green3", lty="dashed", lwd=2)
  legend("topleft", legend=c("fitted SETAR3", "c1", "c2"), col=c("blue", "brown3", "green3"), lty=c(1,2,2), lwd=2, cex=0.8)
  
  plot(x=dat$time[1:plotNmax], y=model$residuals[1:plotNmax], type="l", 
       main=paste0(name," Residuals"),
       xlab="year", ylab="%")
}
```

### 4.6 Conclusion

Due to our limited sampling space of `delays` we obtained `r length(orders3)` possible $SETAR3(p, d, c_1, c_2)$ models, and since remaining
SETAR3 nonlinearity was detected in `r length(nonlinear)` of the original SETAR2 models, we replace them by the top `r length(nonlinear)`
newly found SETAR3's:

```{r}
# set regime count of old models to 2
for (i in 1:length(models)) {
  models[[ orders[i] ]]$nReg <- 2;
  models[[ orders[i] ]]$name <- getModelName(models[[ orders[i] ]])
}
# replace nonlinear
for (i in 1:length(nonlinear)) {
  models[[ nonLinOrders[i] ]] <- models3[[ orders3[i] ]]
}
BICs_revised <- sapply(models, function(m) m$BIC)
orders <- order(BICs_revised)

model_cols <- list()
for (i in 1:12) {
  p <- models[[ orders[i] ]]$p; d <- models[[ orders[i] ]]$d;
  c <- round(ifelse(models[[ orders[i] ]]$c > 1, models[[ orders[i] ]]$c, c(models[[ orders[i] ]]$c, NA)), digits=3)
  model_cols[[i]] <- c(model=models[[ orders[i] ]]$name, BIC=round(models[[ orders[i] ]]$BIC, digits=3))
}

model_cols <- unlist(model_cols)
model_cols <- data.frame(matrix(unlist(model_cols), nrow=12, byrow=T))
names(model_cols) <- c("model", "BIC")
model_cols
```

## 5. Predictions via SETAR Models and Their Evaluation

### 5.1 Helper functions

Since we have not yet defined a skeleton function, i.e. one that would continue plugging in the time series values even after the end of
testing data. For that purpose we implement a step-forward function for an $m$-regime SETAR:

```{r setarOneStep, echo=T}
SETAR_m_singleStep <- function(model, x, t) {
  m <- model$nReg; n <- model$n;
  p <- model$p; d <- model$d; c <- model$c; 
  # parameter matrix with regime coefficients by row
  Phi <- matrix(model$PhiParams, nrow=m)
  
  # extract regime vector
  X <- Xt_m(x, t, p, d, c, m)
  reg_id <- which(colSums(X!=0)!=0)
  x_reg <- X[,reg_id]
  Phi[reg_id,] %*% x_reg
}
```

We can test it on a particular SETAR model:

```{r setarStepTest, echo=T}
n_ahead <- 1
model <- models[[ orders[3] ]]
x_out <- c(x_train, rep(0, n_ahead)); nt <- length(x_train)
  
for (i in 1:n_ahead) {
  x_out[nt + i] <- SETAR_m_singleStep(model, x_out, nt + i)
}
xt <- c(xt, x_eval) # fuse test and eval data
```
```{r}
cat("x_out: "); x_out[nt:(nt + n_ahead)]
cat("data: "); xt[nt:(nt + n_ahead)]
```

This is a single-step prediction of the data using the first model. When we set `n_ahead > 1`, the step function builds up
upon previous predicted values and the skeleton converges to a model's particular equilibrium:

```{r}
n_ahead <- length(x_eval) - 1
model <- models[[ orders[3] ]]
x_out <- c(x_train, rep(0, n_ahead)); nt <- length(x_train)
  
for (i in 1:n_ahead) {
  x_out[nt + i] <- SETAR_m_singleStep(model, x_out, nt + i)
}
data.frame(cbind(x_out=x_out[nt:(nt + n_ahead)], data=xt[nt:(nt + n_ahead)]))
cat("\n equilibria: "); model$equilibria
```

If the model is explosive, the predictions will diverge:

```{r setarNaive, fig.width=10, fig.height=4}
par(mfrow=c(1,2))
n_ahead <- 18;
nt <- length(x_train)
history <- as.integer(0.075 * nt)
for (i in 1:12) {
  model <- models[[ orders[i] ]]
  x_out <- c(x_train, rep(0, n_ahead)); 
  
  for (i in 1:n_ahead) {
    x_out[nt + i] <- SETAR_m_singleStep(model, x_out, nt + i)
  }
  plt_range <- 1.3 * c(min(c(x_out, xt), na.rm=T), max(c(x_out, xt), na.rm=T))
  time_range <- (nt - history):(nt + n_ahead)
  
  c <- model$c
  if (length(c) > 1) {
    plot(x=dat$time[time_range],y=xt[time_range], type="b", lwd=2,
       ylim=plt_range, main=paste(model$name,"naive cumulative pred"), xlab="t", ylab="x[%]")
    lines(x=dat$time[time_range], y=x_out[time_range], col="blue2", lwd=2)
    lines(x=c(dat$time[(nt-history)], dat$time[(nt + n_ahead)]), y=c(c[1],c[1]), col="brown3", lty="dashed", lwd=2)
    lines(x=c(dat$time[(nt-history)], dat$time[(nt + n_ahead)]), y=c(c[2],c[2]), col="green3", lty="dashed", lwd=2)
    legend("topleft", legend=c("data", paste0(n_ahead,"-step"), "c1", "c2"), col=c("black", "blue", "brown3", "green3"), 
           lty=c(NA, 1, 2, 2), pch=c(1, NA, NA, NA), lwd=2, cex=0.8)
  } else {
    plot(x=dat$time[time_range],y=xt[time_range], type="b", lwd=2,
       ylim=plt_range, main=paste(model$name,"naive cumulative pred"), xlab="t", ylab="x[%]")
    lines(x=dat$time[time_range], y=x_out[time_range], col="blue2", lwd=2)
    lines(x=c(dat$time[(nt-history)], dat$time[(nt + n_ahead)]), y=c(c,c), col="green3", lty="dashed", lwd=2)
    legend("topleft", legend=c("data", paste0(n_ahead,"-step"), "c"), col=c("black", "blue", "green3"), 
           lty=c(NA, 1, 2), pch=c(1, NA, NA), lwd=2, cex=0.8)
  }
}

```

The examples above tested `r n_ahead` steps of a naiive approach to prediction, by assuming the process evolves via its skeleton. 
More convenient approaches are `Monte Carlo` (`"MC"`) and `Bootstrap`. Both rely on adding noise to series predictions. Monte Carlo approach
simulates normally distributed noise $\epsilon \sim N(0, \hat{\sigma}_{\varepsilon})$ from residual standard error $\hat{\sigma}_{\varepsilon}$, and
Bootstrap, on the other hand, does not assume the normality of model residuals and instead randomly samples the residuals themselves.

We will use these two approaches in the following implementation:

```{r setarPredict, echo=T}
PredictSETAR <- function(
  model, x_train, x_eval, horizon=(length(x_eval) + 1), n_ahead=1, 
  type=c("naive", "MC", "bootstrap"), Nboot=100, alpha=0.2, refit=F,
  single.step=F, return.paths=F) {

  type <- match.arg(type)
  
  p <- model$p;  d <- model$d; # model dims

  if(missing(x_train)) {
    x_train = model$data # training sample
  }
  
  # result series
  x_res <- x_train
  # training sample size
  nt <- length(x_res)
  sd_res <- sqrt(model$resSigmaSq)

  # extract model residuals
  resid <- as.numeric(model$residuals)
  resid <- resid[!is.na(resid)]
  
  # fill the prediction part of the array with zeros
  x_res <- c(x_res, rep(0, horizon))
  xrange <- p - ((p - 1):0)
  
  if(type=="naive") Nboot <- 1
  
  predictions <- function(x_res, eval.model=model, tmin=nt) {
    noise <- switch(
      type, 
        "naive"= rep(0, n_ahead), 
        "MC"= rnorm(n_ahead, mean = 0, sd=sd_res), 
        "bootstrap" = sample(resid, size=n_ahead, replace=T)
    )

    for(t in (tmin + (1:n_ahead))) {
      x_res[t] <- SETAR_m_singleStep(eval.model, x_res, t)
      x_res[t] <- x_res[t] + noise[t - tmin]
    }
    
    if (!single.step) {
      return(x_res)
    }
    return(x_res[tmin + n_ahead])
  }

  if(single.step) {
    n_ahead <- 1
    x_data <- c(x_train, x_eval)
    if (nt + horizon > length(x_data)) horizon <- (length(x_eval) + 1)
    
    c <- model$c; m <- model$nReg
    if (refit) {
      fit_model <- EstimSETAR_m_postproc( EstimSETAR_m(x_data, p, d, c, m) )
    } else {
      fit_model <- model
    }
    
    x_simulations <- matrix(rep(x_data[nt], Nboot), ncol=Nboot)
    for (t in (nt + 1:horizon)) {
      x_source <- x_data[1:(t - 1)]
      x_simulations <- rbind(x_simulations, replicate(Nboot, 
            predictions(x_source, eval.model=fit_model, tmin=(t - 1))
      ))
      x_res[t] <- mean(x_simulations[t - nt,])
    }
    x_pred <- x_res[nt + 1:horizon]
  } else {
    # === MULTISTEP ===
    if (n_ahead == 1) n_ahead <- horizon

    x_simulations <- replicate(Nboot, predictions(x_res))
    x_sim_means <- rowMeans(x_simulations, na.rm=T)
    x_pred <- x_sim_means[(nt - 1) + 1:n_ahead]
  }
      
  # if not naive compute conf. intervals:
  x_errors <- x_pred
  if(type != "naive") {
    x_errors <- t(apply(
      x_simulations[(nt - 1) * (!single.step) + 1:horizon, ,drop=F], MARGIN=1, quantile, 
      prob=sort(c(alpha, 1 - alpha)), na.rm=T))
  }
  
  # compute prediction errors
  MSE <- sum((x_eval[1:horizon] - x_pred)^2, na.rm=T) / horizon
  # RMSE <- sqrt(MSE)

  if(type == "naive"){
    result <- list(pred=x_pred, MSE=MSE)
  } else {
    if (return.paths) result <- list(pred=x_pred, se=x_errors, MSE=MSE, alpha=alpha,
                                     paths=x_simulations[(nt - 1) * (!single.step) + 1:horizon,])
    else result <- list(pred=x_pred, se=x_errors, MSE=MSE, alpha=alpha)
  }
  
  return(result)
}
```

Now we test it on our data:

```{r}
n_ahead <- 10; precision <- 3;
cat(paste0("naive (",n_ahead,"-step):\n"))
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, horizon=n_ahead)$pred, digits=precision))
cat(paste0("Monte Carlo (",n_ahead,"-step):\n"))
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, type="MC", horizon=n_ahead)$pred, digits=precision))
cat(paste0("Bootstrap (",n_ahead,"-step):\n"))
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, type="bootstrap", horizon=n_ahead)$pred, digits=precision))
cat("data:\n"); xt[nt:(nt + n_ahead)]

```
```{r}
cat("naive (1-step):\n")
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, single.step=T, horizon=n_ahead)$pred, digits=precision))
cat("Monte Carlo (1-step):\n")
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, single.step=T, horizon=n_ahead, type="MC")$pred, digits=precision))
cat("Bootstrap (1-step):\n")
c(xt[nt], round(PredictSETAR(model, x_train, x_eval, single.step=T, horizon=n_ahead, type="bootstrap")$pred, digits=precision))
cat("data:\n"); xt[nt:(nt + n_ahead)]
```

To test other prediction results, such as confidence intervals and simulation paths, we implement a plot procedure:

```{r}
predictSETAR_andPlot <- function(
  model, time, x_train, x_eval, pred_type=c("naive", "MC", "bootstrap"),
  single.step=T, plot.paths=T, print.rmse=T, alpha=0.2, plot.leg=F, legend.pos="top"
) {
  ne <- length(x_eval); nt <- length(x_train)
  xt <- c(x_train, x_eval)
  
  if (pred_type == "naive" && plot.paths) plot.paths <- F # no reason to plot paths of a naive pred
  if (single.step) { n_ahead <- 1 } else { n_ahead <- ne + 1} 

  predict <- PredictSETAR(model, x_train, x_eval, single.step=single.step, n_ahead=n_ahead, type=pred_type, return.paths=plot.paths, alpha=alpha)
  x <- predict$pred
  
  err_low <- predict$se[,1]
  err_high <- predict$se[,2]
  
  x_paths <- predict$paths
  
  history <- as.integer(0.02 * nt)
  x_all <- c(xt, x, err_low, err_high, x_paths)
  plt_range <- 1.3 * c(min(x_all, na.rm=T), max(x_all, na.rm=T))
  time_range <- (nt - history):(nt + ne)
  pred_range <- 1:(ne + 1)
  
  c <- model$c

  method_name <- paste0(
    switch(pred_type, "naive" = "Naive", "MC" = "Monte Carlo", "boot" = "Bootstrap"), 
    " (", n_ahead, "-step) ", ifelse(plot.paths, "sim", ""), ifelse(print.rmse, paste(", RMSE =", round(sqrt(predict$MSE), digits=4)), ""))
  method_name_short <- paste0(pred_type, " (", n_ahead, "-step) ")
  
  if (plot.leg) {
    if (length(c) > 1) {
      legend_names <- c("data", method_name_short, 
                        ifelse(pred_type != "naive", paste0((1 - predict$alpha) * 100,"% conf.interval   "), NA), "c1", "c2", ifelse(plot.paths, "paths", NA))
      legend_col <- c("black", "dodgerblue3", ifelse(pred_type != "naive", "dodgerblue2", NA), "brown3", "green3", ifelse(plot.paths, gray(0.6, alpha=0.2), NA))
      legend_lty <- c(NA, 1, ifelse(pred_type != "naive", 2, NA), 2, 2, ifelse(plot.paths, 1, NA))
      legend_pch <- c(1, NA, NA, NA, NA, NA)
      legend_lwd <- c(2, 2, ifelse(pred_type != "naive", 2, NA), 2, 2, ifelse(plot.paths, 1, NA))
    } else {
      legend_names <- c("data", method_name_short, 
                        ifelse(pred_type != "naive", paste0((1 - predict$alpha) * 100,"% conf.interval   "), NA), "c", ifelse(plot.paths, "paths", NA))
      legend_col <- c("black", "dodgerblue3", ifelse(pred_type != "naive", "dodgerblue2", NA), "green3", ifelse(plot.paths, gray(0.6, alpha=0.2), NA))
      legend_lty <- c(NA, 1, ifelse(pred_type != "naive", 2, NA), 2, ifelse(plot.paths, 1, NA))
      legend_pch <- c(1, NA, NA, NA, NA)
      legend_lwd <- c(2, 2, ifelse(pred_type != "naive", 2, NA), 2, ifelse(plot.paths, 1, NA))
    }    
  }
  
  plot(x=dat$time[time_range],y=xt[time_range], type="b", lwd=2,
     ylim=plt_range, main=paste(model$name, method_name), xlab="t", ylab="x[%]")
  # conf. interval fill
  if (pred_type != "naive") {
  polygon(
    x=c(time[(nt - 1) + pred_range], rev(time[(nt - 1) + pred_range])), y=c(err_low[pred_range],rev(err_high[pred_range])), 
        col=adjustcolor("dodgerblue2", alpha.f=0.3), border=F)      
  }
  # simulations
  if (plot.paths) matlines(x=matrix(time[(nt - 1) + pred_range], byrow=T), y=x_paths, col=gray(0.6, alpha=0.2), lty=1)
  # x
  lines(x=time[(nt - 1) + pred_range], y=x[pred_range], col="dodgerblue3", lwd=2)
  # conf. intervals
  if (pred_type != "naive") {
    lines(x=time[(nt - 1) + pred_range], y=err_low[pred_range], col="dodgerblue2", lwd=2, lty="dashed")
    lines(x=time[(nt - 1) + pred_range], y=err_high[pred_range], col="dodgerblue2", lwd=2, lty="dashed")        
  }
  # thresholds
  if (length(c) > 1) {
    lines(x=c(time[(nt-history)], time[(nt + ne)]), y=c(c[1],c[1]), col="brown3", lty="dashed", lwd=2)
    lines(x=c(time[(nt-history)], time[(nt + ne)]), y=c(c[2],c[2]), col="green3", lty="dashed", lwd=2)      
  } else {
    lines(x=c(time[(nt-history)], time[(nt + ne)]), y=c(c,c), col="green3", lty="dashed", lwd=2)
  }
  if (plot.leg) {
    legend(legend.pos, horiz=T, legend=legend_names, 
           col=legend_col, 
           lty=legend_lty, 
           pch=legend_pch, lwd=legend_lwd, cex=0.8)    
  }
}

```

```{r predictPlot1, echo=T, fig.width=10, fig.height=3.6}
par(mfrow=c(1, 1))
predictSETAR_andPlot(
  models[[ orders[3] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="MC", single.step=T, plot.paths=F, plot.leg=T)

predictSETAR_andPlot(
  models[[ orders[3] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="MC", single.step=F, plot.paths=T, plot.leg=T)
```

Now we possess all necessary tools to proceed evaluating our SETAR models according to their predictive abilities.

### 5.2 Single-Step Predictions of SETAR Models

#### Naive:

```{r singleStepNaivePlots, fig.width=11, fig.height=3.6}
par(mfrow=c(1, 2))
for (i in 1:12) {
  predictSETAR_andPlot(
  models[[ orders[i] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="naive", single.step=T, plot.paths=F)
}
```

#### Monte Carlo:

```{r singleStepMCPlots, fig.width=11, fig.height=3.6}
par(mfrow=c(1, 2))
for (i in 1:12) {
  predictSETAR_andPlot(
  models[[ orders[i] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="MC", single.step=T, plot.paths=F)
}
```

#### Bootstrap:

```{r singleStepBootPlots, fig.width=11, fig.height=3.6}
par(mfrow=c(1, 2))
for (i in 1:12) {
  predictSETAR_andPlot(
  models[[ orders[i] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="boot", single.step=T, plot.paths=F)
}
```

### 5.3 Multi-Step Predictions of SETAR Models

#### Monte Carlo:

```{r multiStepMCPlots, fig.width=11, fig.height=3.6}
par(mfrow=c(1, 2))
for (i in 1:12) {
  predictSETAR_andPlot(
  models[[ orders[i] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="MC", single.step=F, plot.paths=T)
}
```

#### Bootstrap:

```{r multiStepBootPlots, fig.width=11, fig.height=3.6}
par(mfrow=c(1, 2))
for (i in 1:12) {
  predictSETAR_andPlot(
  models[[ orders[i] ]], time=dat$time, x_train=x_train, x_eval=x_eval, 
  pred_type="boot", single.step=F, plot.paths=T)
}
```

### 5.4 Evaluating Models

From what we observe, some models exhibit explosive properties, and have equilibria significantly distant from the evaluated data set, which,
of course, impacts the resulting prediction error. Now we evaluate models according to their predictive properties, and filter out those that
produce distant and/or explosive predictions.

```{r}
se_factor <- 4
model_cols_mse <- cbind(model_cols, rss=rep(0, 12), MSE_naive=rep(0, 12), MSE_mc=rep(0, 12), MSE_boot=rep(0, 12), divergence=rep("", 12), stringsAsFactors=F)
for (i in 1:12) {
  #i <- 1
  model <- models[[ orders[i] ]];
  # prediction errors have to be computed again since passing model to predictSETAR_andPlot does not
  # pass reference, only a copy
  predict1_naive <- PredictSETAR(model, x_train, x_eval, single.step=T, type="naive", return.paths=F)
  predict1_mc <- PredictSETAR(model, x_train, x_eval, single.step=T, type="MC", return.paths=F)
  predict1_boot <- PredictSETAR(model, x_train, x_eval, single.step=T, type="boot", return.paths=F)
  model$mse_naive <- predict1_naive$MSE; model$mse_mc <- predict1_mc$MSE; model$mse_boot <- predict1_boot$MSE
  
  divergent1 <- se_factor * model$resSigmaSq < predict1_naive$MSE
  divergent2 <- se_factor * model$resSigmaSq < predict1_mc$MSE
  divergent3 <- se_factor * model$resSigmaSq < predict1_boot$MSE
  div <- paste(ifelse(divergent1, "!",""), ifelse(divergent2, "!",""), ifelse(divergent3, "!",""))
  
  model_cols_mse[i, 3] <- round(model$resSigmaSq, digits=4); # fill in rss
  model_cols_mse[i, 4] <- round(predict1_naive$MSE, digits=4);
  model_cols_mse[i, 5] <- round(predict1_mc$MSE, digits=4);
  model_cols_mse[i, 6] <- round(predict1_boot$MSE, digits=4);
  model_cols_mse[i, 7] <- div
}
model_cols_mse
```

We notice that models that quickly diverge have significantly higher $MSE$ than their $\hat\sigma_{\varepsilon}^2$ (`rss`). 
One could then formulate a condition that model is "too divergent" if its training data $MSE$ (`rss`) is significantly lower 
than prediction $MSE$. The significance factor could be taken, for example, as `r se_factor`, i.e.: if the prediction $MSE$ exceeds `r se_factor`-multiple 
of training data `rss`, the prediction diverges. In the above table, we mark divergent predictions with `!`.

### 5.5 Conclusion and SETAR Evaluation

After considering all possible configurations of SETAR models, testing them for remaining nonlinearity, and evaluating their predictive properties,
we conclude the following:

Some models placed within the top 3 best in their fit onto the training data (according to their $BIC$), contained SETAR3-type remaining nonlinearity, 
and thus had their thresholds estimated, turned out to have radically different equilibria than their 2-regime predecessors. Some were even explosive when
we examined their predictive properties. Hence their training data fit quality cannot justify their mismatch between data and their properties as stochastic
dynamical systems.

With regards to their predictive properties, we pick the best models according to their given $MSE$ depending on the prediction method (`"naive"`, `"mc"`, `"boot"`):

```{r}
cat("Models sorted by 1-step naive MSE:\n")
non_divergent <- model_cols_mse[which( sapply(1:12, function(i) nchar(gsub(" ", "", model_cols_mse[i, 7])) == 0) ), ]
mse_naive_orders <- order(non_divergent[, 4])
mse_naive_cols <- non_divergent[mse_naive_orders, ]
mse_naive_cols[, 1:4]
```

```{r}
cat("Models sorted by 1-step Monte Carlo MSE:\n")
#non_divergent <- model_cols_mse[which( sapply(1:12, function(i) nchar(gsub(" ", "", model_cols_mse[i, 7])) == 0) ), ]
mse_mc_orders <- order(non_divergent[, 5])
mse_mc_cols <- non_divergent[mse_mc_orders, ]
cbind(mse_mc_cols[, 1:3], MSE_mc=mse_mc_cols[, 5])
```

```{r}
cat("Models sorted by 1-step Bootstrap MSE:\n")
#non_divergent <- model_cols_mse[which( sapply(1:12, function(i) nchar(gsub(" ", "", model_cols_mse[i, 7])) == 0) ), ]
mse_boot_orders <- order(non_divergent[, 6])
mse_boot_cols <- non_divergent[mse_mc_orders, ]
cbind(mse_boot_cols[, 1:3], MSE_boot=mse_boot_cols[, 6])
```

and as we observe, the order remains the same regardless of the prediction method.

## 6. Tests for Non-Linearity of STAR Models
 